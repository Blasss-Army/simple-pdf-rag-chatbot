---
title: Simple PDF RAG Chatbot
emoji: âš¡
colorFrom: red
colorTo: gray
sdk: gradio
app_file: app.py
pinned: false
license: mit
short_description: Privacy-first RAG chatbot to query your PDFs with citations.
sdk_version: 5.49.1
---
# ğŸ“˜ Simple PDF RAG Chatbot (Gradio + Gemini + Qdrant)

A production-ready **Retrieval-Augmented Generation (RAG)** chatbot designed to answer questions based on your own **PDF documents**.  
It uses **Google Gemini** for language generation, **text-embedding-004** for semantic embeddings, and a **local Qdrant vector database** for efficient similarity search â€” all wrapped in a clean **Gradio** web interface.

> ğŸš€ Built as a portfolio-ready project to demonstrate skills in LLM orchestration, retrieval pipelines, embeddings, and end-to-end GenAI application development.

---

## âœ¨ Features
- ğŸ“„ **Ask questions about your PDFs** and get **accurate, cited answers** with page references.  
- ğŸ§  **Retrieval-Augmented Generation pipeline** built with LangChain, Gemini, and Qdrant.  
- ğŸ—ƒï¸ **Local vector storage** (Qdrant Path Mode) â€” no external database or cloud required.  
- ğŸ” **Dynamic retriever settings** adjustable directly from the UI.  
- ğŸ§¬ **Deterministic chunk IDs** ensure reproducible citations and safe re-indexing.  
- ğŸ’¬ **Conversational memory** remembers previous context across turns.  
- ğŸŒ **Cross-platform compatible** and ready for deployment or containerization.
- ğŸ“„**Drop PDFs in a folder** â†’ ask questions and get **cited answers** with page numbers.

---

## ğŸ§± Tech Stack

- **LLM:** [Google Gemini](https://deepmind.google/technologies/gemini/) (`gemini-2.0-flash`)
- **Embeddings:** Google `text-embedding-004`
- **Vector Database:** [Qdrant](https://qdrant.tech/) (local path mode)
- **Frameworks:** [LangChain](https://www.langchain.com/) + [Gradio](https://www.gradio.app/)
- **Language:** Python 3.10+
- **Environment:** `.env` for API keys (`GOOGLE_API_KEY`)

---

## ğŸ—ï¸ System Architecture

```text
User (Gradio UI)
   â””â”€â”€ Chat()  â”€â”€(ConversationalRetrievalChain)â”€â”€â–º LLM (Gemini)
         â”‚
         â”œâ”€â–º Retriever (Qdrant + Embeddings)
         â”‚      â”œâ”€ Load PDFs â†’ Split into chunks
         â”‚      â”œâ”€ Embed with Google text-embedding-004
         â”‚      â””â”€ Store vectors in local Qdrant (path = ./index)
         â”‚
         â””â”€â–º Memory (ConversationBufferMemory)
```

---

## ğŸ“‚ Project Structure

```
P1-Simple PDF RAG Chatbot/
â”œâ”€ app_core/
â”‚  â”œâ”€ __init__.py
â”‚  â”œâ”€ prompt.py           # Prompt templates for the LLM
â”‚  â””â”€ llm_call.py         # Main Chat class (chain, memory, retriever orchestration)
â”œâ”€ create_retriever/
â”‚  â”œâ”€ __init__.py
â”‚  â”œâ”€ conf.py             # RetrieverConfig dataclass
â”‚  â””â”€ retriever.py        # PDF loading, chunking, embedding, Qdrant setup
â”œâ”€ ui/
â”‚  â”œâ”€ __init__.py
â”‚  â”œâ”€ gradio_app.py       # Gradio UI logic
â”‚  â””â”€ style.py            # Reusable HTML UI components
â”œâ”€ data/                  # Place your PDFs here
â”œâ”€ index/                 # Local Qdrant vector store
â”œâ”€ app.py                 # runner for Hugging Face
â”œâ”€ main.py                # runner for Git Hub
â”œâ”€ .env                   # API keys (GOOGLE_API_KEY)
â””â”€ README.md
```

---

## âš™ï¸ Configuration

The behavior of the retriever is controlled via `create_retriever/conf.py`:

```python
@dataclass
class RetrieverConfig:
    data_path: Path = PROJECT_ROOT / "data"
    index_path: Path = PROJECT_ROOT / "index"
    collection_name: str = "my_collection"
    embed_model: str = "models/text-embedding-004"
    distance: Distance = Distance.COSINE
    prefer_grpc: bool = True
    reset_collection: bool = False
    vectore_store_search_type: str = "mmr"
    vectore_store_k: int = 5
    vectore_store_fetch_k: int = 30
    vectore_store_lambda_mult: float = 0.5
```

ğŸ’¡ **Tip:** Set `reset_collection=True` the first time or whenever you want to rebuild the index from scratch.

---

## ğŸš€ Getting Started

### 1ï¸âƒ£ Install Requirements

```bash
git clone <your-repo-url>
cd P1-Simple-PDF-RAG-Chatbot
python -m venv .venv
source .venv/bin/activate  # Windows: .venv\Scripts\activate

pip install -U pip
pip install langchain langchain-community langchain-google-genai qdrant-client gradio python-dotenv
```

---

### 2ï¸âƒ£ Set Environment Variables

Create a `.env` file in the project root:

```bash
GOOGLE_API_KEY=your_api_key_here
```

---

### 3ï¸âƒ£ Add PDFs

Place your documents inside the `data/` folder:

```
data/
â”œâ”€ my_file.pdf
â”œâ”€ research_paper.pdf
â””â”€ report.pdf
```

---

### 4ï¸âƒ£ Run the App

```bash
python app.py
```

Once started, open your browser at:  
ğŸ‘‰ http://127.0.0.1:7860

---

## ğŸ§  How It Works

1. PDFs are loaded and split into overlapping text chunks (`RecursiveCharacterTextSplitter`).
2. Each chunk is embedded using `text-embedding-004`.
3. Vectors are stored in Qdrant and retrieved with **MMR search**.
4. Retrieved context + user query are passed to **Gemini**, which generates a grounded, cited answer.
5. Responses include references (file + page) and use conversational memory for context-aware conversations.

---

## ğŸ› ï¸ Key Improvements in This Version

- âœ… **Chain bug fix:** `_make_chain()` now returns a valid `ConversationalRetrievalChain`.  
- âœ… **Retriever refactor:** duplicate insertions removed and retrieval logic improved.  
- âœ… **Dynamic updates:** retriever settings can be modified from the UI without restarting the app.  
- âœ… **Cross-platform:** source file paths now handled with `os.path.basename()`.
- âœ… **English documentation:** all code comments and docstrings are in English for readability.  
- âœ… **Cleaner UI:** all interface labels standardized and improved for demo purposes.

---

## ğŸ§ª Recommended Tests

- Upload multiple PDFs and query across them.  
- Adjust retrieval settings (e.g., `k`, `lambda_mult`) to see real-time impact.  
- Clear memory and test context retention across turns.  
- Verify citation stability across repeated runs (deterministic IDs).  

---

## ğŸ“ˆ Future Enhancements

- ğŸ” Hybrid lexical-vector retrieval  
- ğŸ“Š Cross-encoder reranking  
- ğŸŒ Multilingual question answering  
- ğŸ“‘ Clickable citations with direct PDF previews  
- âš¡ FastAPI backend and REST API endpoints  
- ğŸ³ Docker deployment with one-command startup

---

## ğŸ“œ License

This project is released under the **MIT License**.  
See [LICENSE](./LICENSE) for details.

---

## ğŸ™Œ Acknowledgements

- [LangChain](https://python.langchain.com/)  
- [Qdrant](https://qdrant.tech/)  
- [Gradio](https://www.gradio.app/)  
- [Google Gemini](https://deepmind.google/technologies/gemini/)

---

### â­ Quick Demo

```bash
# Clone & run in minutes
git clone <your-repo-url>
cd P1-Simple-PDF-RAG-Chatbot
pip install -r requirements.txt
echo "GOOGLE_API_KEY=..." > .env
mkdir data && cp your.pdf data/
python app.py
```
